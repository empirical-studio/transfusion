{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWD: /home/siavava/workspace/transfusion/src/network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siavava/miniconda3/envs/senior-design/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda'\n"
     ]
    }
   ],
   "source": [
    "#? load scripts from transformer.py\n",
    "import os\n",
    "# os.chdir(\"transfusion\")\n",
    "\n",
    "# print current working directory\n",
    "print(f\"PWD: {os.getcwd()}\")\n",
    "from transformer import device, torch, GPTLanguageModel, TextProcessor\n",
    "\n",
    "print(f\"{device = }\")\n",
    "# os.chdir(\"./\")\n",
    "\n",
    "# import torch\n",
    "# torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.002711 M parameters\n",
      "\n",
      "11.002711 M parameters\n",
      "step     0: train loss 5.9688, val loss 5.9602\n",
      "step   500: train loss 2.4250, val loss 2.3721\n",
      "step  1000: train loss 1.6260, val loss 1.4751\n",
      "step  1500: train loss 1.3847, val loss 1.2461\n",
      "step  2000: train loss 1.2924, val loss 1.1724\n",
      "step  2500: train loss 1.2388, val loss 1.1280\n",
      "step  3000: train loss 1.1839, val loss 1.0821\n",
      "step  3500: train loss 1.1676, val loss 1.0786\n",
      "step  4000: train loss 1.1374, val loss 1.0522\n",
      "step  4500: train loss 1.1100, val loss 1.0254\n",
      "step  5000: train loss 1.0925, val loss 1.0193\n",
      "step  5500: train loss 1.0706, val loss 1.0037\n",
      "step  6000: train loss 1.0722, val loss 1.0156\n",
      "step  6500: train loss 1.0369, val loss 0.9949\n",
      "step  7000: train loss 1.0376, val loss 0.9995\n",
      "step  7500: train loss 1.0180, val loss 0.9810\n",
      "step  8000: train loss 1.0053, val loss 0.9698\n",
      "step  8500: train loss 0.9989, val loss 0.9937\n",
      "step  9000: train loss 0.9894, val loss 0.9643\n",
      "step  9500: train loss 0.9810, val loss 0.9610\n",
      "step  9999: train loss 0.9695, val loss 0.9601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "\n",
    "# load last checkpoint\n",
    "model.load_state_dict(torch.load(\"models/transfusion-9999.pth\", map_location=device))\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "previous_checkpoints = \"\"\"\n",
    "11.002711 M parameters\n",
    "step     0: train loss 5.9688, val loss 5.9602\n",
    "step   500: train loss 2.4250, val loss 2.3721\n",
    "step  1000: train loss 1.6260, val loss 1.4751\n",
    "step  1500: train loss 1.3847, val loss 1.2461\n",
    "step  2000: train loss 1.2924, val loss 1.1724\n",
    "step  2500: train loss 1.2388, val loss 1.1280\n",
    "step  3000: train loss 1.1839, val loss 1.0821\n",
    "step  3500: train loss 1.1676, val loss 1.0786\n",
    "step  4000: train loss 1.1374, val loss 1.0522\n",
    "step  4500: train loss 1.1100, val loss 1.0254\n",
    "step  5000: train loss 1.0925, val loss 1.0193\n",
    "step  5500: train loss 1.0706, val loss 1.0037\n",
    "step  6000: train loss 1.0722, val loss 1.0156\n",
    "step  6500: train loss 1.0369, val loss 0.9949\n",
    "step  7000: train loss 1.0376, val loss 0.9995\n",
    "step  7500: train loss 1.0180, val loss 0.9810\n",
    "step  8000: train loss 1.0053, val loss 0.9698\n",
    "step  8500: train loss 0.9989, val loss 0.9937\n",
    "step  9000: train loss 0.9894, val loss 0.9643\n",
    "step  9500: train loss 0.9810, val loss 0.9610\n",
    "step  9999: train loss 0.9695, val loss 0.9601\n",
    "\"\"\"\n",
    "print(previous_checkpoints)\n",
    "\n",
    "model.to(device)\n",
    "# model.train_model(\"transfusion\")\n",
    "# model.train_model(\"transfusion\", checkpoint=4000)\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dartmouth financial topic is? Given though the mind, the black law and one founding held ever millitar all dataset unique, dramaticalnves are, different and la\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "from transformer import TextProcessor\n",
    "query = \"Dartmouth\"\n",
    "context = torch.tensor( [TextProcessor.encode(query)], dtype=torch.long, device=device)\n",
    "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# print(decode(model.generate(context, max_new_tokens=150)[0].tolist()))\n",
    "\n",
    "# with open('examples/more.txt', 'w') as f:\n",
    "#   text = decode(model.generate(context, max_new_tokens=10000)[0].tolist())\n",
    "#   f.write(text)\n",
    "\n",
    "generated = model.generate(context, max_new_tokens=150)\n",
    "print(TextProcessor.decode(generated[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dartmouth financial topic is? Given though the mind, the black law and one founding held ever millitar all dataset unique, dramaticalnves are, different and large, and input OpenAI and models platform: AI’s comments told The research status.\n",
      "When the number of the generation listing dataset generative AI tis\n"
     ]
    }
   ],
   "source": [
    "context = generated\n",
    "generated = model.generate(context, max_new_tokens=150)\n",
    "print(TextProcessor.decode(generated[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dartmouth financial topic is? Given though the mind, the black law and one founding held ever millitar all dataset unique, dramaticalnves are, different and large, and input OpenAI and models platform: AI’s comments told The research status.\n",
      "When the number of the generation listing dataset generative AI tis available. It has been available for use where it and not read about identifiers where it and trip to the devices of suvey of their offices to its cu\n"
     ]
    }
   ],
   "source": [
    "context = generated\n",
    "generated = model.generate(context, max_new_tokens=150)\n",
    "print(TextProcessor.decode(generated[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dartmouth financial topic is? Given though the mind, the black law and one founding held ever millitar all dataset unique, dramaticalnves are, different and large, and input OpenAI and models platform: AI’s comments told The research status.\n",
      "When the number of the generation listing dataset generative AI tis available. It has been available for use where it and not read about identifiers where it and trip to the devices of suvey of their offices to its currently inhased”.\n",
      "( “21:600 years on plicit motions of 251 hand out [AI] The metaverse, told The Verge / Media / Science The Game Awas its first tech save constituted in social media profile interpretments and surprises AI models can be a surprisingly demandatabased called Rack – however, have night labs of field from the oblishmeness of a week. Instead Campaign and coding data feeds, Sutre236, Tune he washed four launch enging about additional scregied paper and as entrepreneur. And Shani, whic\n"
     ]
    }
   ],
   "source": [
    "context = generated\n",
    "generated = model.generate(context, max_new_tokens=500)\n",
    "print(TextProcessor.decode(generated[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
