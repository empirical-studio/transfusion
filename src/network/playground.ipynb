{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import display markdown\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Tiny Shakespeare Dataset\n",
       "  | Metric | Value |\n",
       "  | --- | --- |\n",
       "  | Number of characters | 45464039 |\n",
       "  | Number of unique characters | 343 |\n",
       "  | Number of lines | 119877 |\n",
       "  | Number of words | 7383298 |\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import datasets\n",
    "\n",
    "# # load tiny shakespeare dataset\n",
    "# # dataset = datasets.load_dataset('tiny_shakespeare', cache_dir=\"cache\")\n",
    "\n",
    "dataset = datasets.load_dataset('siavava/ai-tech-articles', split='train')\n",
    "df = dataset.to_pandas()\n",
    "df = df[df[\"year\"] == 2023]\n",
    "\n",
    "# concat all \"text\" column values into one string\n",
    "text = \" \".join(df[\"text\"].tolist())\n",
    "# print(text)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"../data/input.txt\", \"r\") as f:\n",
    "#   text = f.read()\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Tiny Shakespeare Dataset\n",
    "  | Metric | Value |\n",
    "  | --- | --- |\n",
    "  | Number of characters | {len(text)} |\n",
    "  | Number of unique characters | {len(set(text))} |\n",
    "  | Number of lines | {len(text.splitlines())} |\n",
    "  | Number of words | {len(text.split())} |\n",
    "  \"\"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Encoding and Decoding\n",
       "  | Text | Encoded | Decoded |\n",
       "  | --- | --- | --- |\n",
       "  | \"The Verge | [3, 53, 72, 69, 1, 55, 69, 82, 71, 69] | \"The Verge |\n",
       "  | eserved.\n",
       " | [69, 83, 69, 82, 86, 69, 68, 15, 0, 3] | eserved.\n",
       "\" |     \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STOI = {ch: i for i, ch in enumerate(sorted(set(text)))}\n",
    "ITOS = {i: ch for ch, i in STOI.items()}\n",
    "\n",
    "def encode(text: str):\n",
    "  return [STOI[ch] for ch in text]\n",
    "\n",
    "def decode(indices: list):\n",
    "  return ''.join(ITOS[i] for i in indices)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Encoding and Decoding\n",
    "  | Text | Encoded | Decoded |\n",
    "  | --- | --- | --- |\n",
    "  | {text[:10]} | {encode(text[:10])} | {decode(encode(text[:10]))} |\n",
    "  | {text[-10:-1]} | {encode(text[-10:])} | {decode(encode(text[-10:]))} |     \n",
    "  \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 73, 1, 84, 72, 69, 82, 69]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hi there\"))\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 53, 72, 69,  1, 55, 69, 82, 71, 69,  1, 72, 79, 77, 69, 80, 65, 71,\n",
       "        69,  1, 53, 72, 69,  1, 55, 69, 82, 71, 69,  1, 72, 79, 77, 69, 80, 65,\n",
       "        71, 69,  1, 53, 72, 69,  1, 55, 69, 82, 71, 69,  1, 53, 72, 69,  1, 55,\n",
       "        69, 82, 71, 69,  1, 76, 79, 71, 79, 15,  0, 16,  1, 53, 69, 67, 72,  1,\n",
       "        16,  1, 51, 69, 86, 73, 69, 87, 83,  1, 16,  1, 52, 67, 73, 69, 78, 67,\n",
       "        69,  1, 16,  1, 38, 78, 84, 69, 82, 84])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text))\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Train and Validation Data\n",
       "  | Data | Length |\n",
       "  | --- | --- |\n",
       "  | Train | 36371231 |\n",
       "  | Validation | 9092808 |\n",
       "  | **Total** | **45464039** |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = int(len(data) * 0.8)\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Train and Validation Data\n",
    "  | Data | Length |\n",
    "  | --- | --- |\n",
    "  | Train | {len(train_data)} |\n",
    "  | Validation | {len(val_data)} |\n",
    "  | **Total** | **{len(train_data) + len(val_data)}** |\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Batch Data\n",
       "  | Data | Shape |\n",
       "  | --- | --- |\n",
       "  | Inputs | torch.Size([4, 8]) |\n",
       "  | Targets | torch.Size([4, 8]) |\n",
       "\n",
       "  Inputs: tensor([[78, 75,  1, 79, 80, 69, 78, 83],\n",
       "        [73, 69, 87,  1, 83, 65, 86, 69],\n",
       "        [79, 84,  1, 46, 73, 67, 82, 79],\n",
       "        [76,  1, 83, 75, 73, 76, 76, 83]])  \n",
       "  Targets: tensor([[75,  1, 79, 80, 69, 78, 83,  1],\n",
       "        [69, 87,  1, 83, 65, 86, 69, 68],\n",
       "        [84,  1, 46, 73, 67, 82, 79, 83],\n",
       "        [ 1, 83, 75, 73, 76, 76, 83, 13]]) \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)       # Set the random seed for reproducibility\n",
    "CONTEXT_LENGTH = 8            # Maximum context length.\n",
    "BATCH_SIZE = 4                # Number of independent sequences to train on in parallel\n",
    "\n",
    "def get_batch(split: str):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  start_idx = torch.randint(0, len(data) - CONTEXT_LENGTH, (BATCH_SIZE,))\n",
    "  end_idx = start_idx + CONTEXT_LENGTH\n",
    "  inputs = [data[start:end] for start, end in zip(start_idx, end_idx)]\n",
    "  targets = [data[start+1:end+1] for start, end in zip(start_idx, end_idx)]\n",
    "  return torch.stack(inputs), torch.stack(targets)\n",
    "\n",
    "inputs, targets = get_batch('train')\n",
    "display(Markdown(f\"\"\"\n",
    "  # Batch Data\n",
    "  | Data | Shape |\n",
    "  | --- | --- |\n",
    "  | Inputs | {inputs.shape} |\n",
    "  | Targets | {targets.shape} |\n",
    "\n",
    "  Inputs: {inputs}  \n",
    "  Targets: {targets} \n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 53, 72, 69,  1, 55, 69, 82, 71])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Contexts and Targets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3]) -> 53\n",
      "tensor([ 3, 53]) -> 72\n",
      "tensor([ 3, 53, 72]) -> 69\n",
      "tensor([ 3, 53, 72, 69]) -> 1\n",
      "tensor([ 3, 53, 72, 69,  1]) -> 55\n",
      "tensor([ 3, 53, 72, 69,  1, 55]) -> 69\n",
      "tensor([ 3, 53, 72, 69,  1, 55, 69]) -> 82\n",
      "tensor([ 3, 53, 72, 69,  1, 55, 69, 82]) -> 71\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "display(Markdown(\"### Contexts and Targets\"))\n",
    "for t in range(block_size):\n",
    "  context = x[:t+1]\n",
    "  target = y[t]\n",
    "  print(f\"{context} -> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
      "        [-0.8109,  0.2410, -0.1139,  ...,  1.4509,  0.1836,  0.3064],\n",
      "        ...,\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [-0.1679,  0.5602,  0.6467,  ...,  0.1522,  0.5109,  0.0990],\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594]],\n",
      "       grad_fn=<ViewBackward0>), tensor(4.5193, grad_fn=<NllLossBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "  def __init__(self, vocab_size: int):\n",
    "    super().__init__()\n",
    "    self.embeddings = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "  def forward(self, idx, targets=None):\n",
    "\n",
    "    logits = self.embeddings(idx)\n",
    "    if targets is None:\n",
    "      loss = None\n",
    "\n",
    "    else:\n",
    "      B, T, C = logits.shape\n",
    "      logits = logits.view(B*T, C)\n",
    "      targets = targets.view(B*T)\n",
    "      loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "    return logits, loss\n",
    "  \n",
    "  def generate(self, idx, max_new_tokens):\n",
    "    \"\"\"\n",
    "      idx: (B, T)\n",
    "    \"\"\"\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "      logits, loss = self(idx)\n",
    "\n",
    "      logits = logits[:, -1, :]\n",
    "\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "      idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "      idx = torch.cat([idx, idx_next], dim=-1)\n",
    "\n",
    "    return idx\n",
    "  \n",
    "vocab_size = len(STOI)\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "print(out := model(xb, yb))\n",
    "\n",
    "idx = torch.zeros( (1, 1), dtype=torch.long)\n",
    "decode(model.generate(idx, max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(optimizer := torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TERYourand sted crd ICHador pengle y leathe, sher I chad timise wiselimod\n",
      "BEORI ld thy s\n",
      "The,\n",
      "\n",
      "Pomy, s sknacar se e wes, ofal t whenouroutal,\n",
      "\n",
      "\n",
      "DIENRoug whent\n",
      "S:\n",
      "ENGo w, u in omath ng! me chay othy mat sioubo ind mete l shawanod t t f chefithy t d nts thompo sendyount wo st me wiso ithey gnou whind th t howith t ar t\n",
      "I'd.\n",
      "loong hay theral fimpat bu, heiteceer ong\n",
      "ASecoutou ar,\n",
      "CENENERE ped? d, fre\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(100000):\n",
    "  xb, yb = get_batch('train')\n",
    "  logits, loss = model(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # if steps % 100 == 0:\n",
    "  #   print(f\"Step: {steps:4} Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(decode(model.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yeres! f cooue pu wes N hat pemese bamerte we ono, cthouthe wangeakigl hin asedes m al wal g byo y a\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
